{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows',None)\n",
    "pd.set_option('display.max_columns',None)\n",
    "pd.options.display.max_colwidth = 500\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the files into a dataframe\n",
    "train=pd.read_csv(r'C:\\Users\\dravi\\Desktop\\Lenovo backup\\swathi\\Flip Robo\\Malignant-Comments-Classifier-Project\\Malignant Comments Classifier Project\\train.csv')\n",
    "test=pd.read_csv(r'C:\\Users\\dravi\\Desktop\\Lenovo backup\\swathi\\Flip Robo\\Malignant-Comments-Classifier-Project\\Malignant Comments Classifier Project\\test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>malignant</th>\n",
       "      <th>highly_malignant</th>\n",
       "      <th>rude</th>\n",
       "      <th>threat</th>\n",
       "      <th>abuse</th>\n",
       "      <th>loathe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember what page that's on?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00025465d4725e87</td>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the tools well.  · talk \"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00031b1e95af7921</td>\n",
       "      <td>Your vandalism to the Matt Shirvington article has been reverted.  Please don't do it again, or you will be banned.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00037261f536c51d</td>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to you. Anyway, I'm not intending to write anything in the article(wow they would jump on me for vandalism), I'm merely requesting that it be more encyclopedic so one can use it for school as a reference. I have been to the selective breeding page but it's almost a stub. It points to 'animal breeding' which is a short messy article that gives you no info. There must be someone around with expertise in eugenics? 93.161.107.169</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00040093b2687caa</td>\n",
       "      <td>alignment on this subject and which are contrary to those of DuLithgow</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  \\\n",
       "0  0000997932d777bf   \n",
       "1  000103f0d9cfb60f   \n",
       "2  000113f07ec002fd   \n",
       "3  0001b41b1c6bb37e   \n",
       "4  0001d958c54c6e35   \n",
       "5  00025465d4725e87   \n",
       "6  0002bcb3da6cb337   \n",
       "7  00031b1e95af7921   \n",
       "8  00037261f536c51d   \n",
       "9  00040093b2687caa   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          comment_text  \\\n",
       "0                                                                                                                                                                                                                                            Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                     D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)   \n",
       "2                                                                                                                                                                                                                                                                            Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess t...   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                  You, sir, are my hero. Any chance you remember what page that's on?   \n",
       "5                                                                                                                                                                                                                                                                                                                                                                                                                                                  \"\\n\\nCongratulations from me as well, use the tools well.  · talk \"   \n",
       "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                         COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK   \n",
       "7                                                                                                                                                                                                                                                                                                                                                                                                  Your vandalism to the Matt Shirvington article has been reverted.  Please don't do it again, or you will be banned.   \n",
       "8                             Sorry if the word 'nonsense' was offensive to you. Anyway, I'm not intending to write anything in the article(wow they would jump on me for vandalism), I'm merely requesting that it be more encyclopedic so one can use it for school as a reference. I have been to the selective breeding page but it's almost a stub. It points to 'animal breeding' which is a short messy article that gives you no info. There must be someone around with expertise in eugenics? 93.161.107.169   \n",
       "9                                                                                                                                                                                                                                                                                                                                                                                                                                               alignment on this subject and which are contrary to those of DuLithgow   \n",
       "\n",
       "   malignant  highly_malignant  rude  threat  abuse  loathe  \n",
       "0          0                 0     0       0      0       0  \n",
       "1          0                 0     0       0      0       0  \n",
       "2          0                 0     0       0      0       0  \n",
       "3          0                 0     0       0      0       0  \n",
       "4          0                 0     0       0      0       0  \n",
       "5          0                 0     0       0      0       0  \n",
       "6          1                 1     1       0      1       0  \n",
       "7          0                 0     0       0      0       0  \n",
       "8          0                 0     0       0      0       0  \n",
       "9          0                 0     0       0      0       0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll ever be whats up with you and hating you sad mofuckas...i should bitch slap ur pethedic white faces and get you to kiss my ass you guys sicken me. Ja rule is about pride in da music man. dont diss that shit on him. and nothin is wrong bein like tupac he was a brother too...fuckin white boys get things right next time.,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is, IMO.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lapland —  /  \"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the information I updated was the correct form. I can only guess the source hadn't updated. I shall update the information once again but thank you for your message.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0001ea8717f6de06</td>\n",
       "      <td>Thank you for understanding. I think very highly of you and would not revert without discussion.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00024115d4cbde0f</td>\n",
       "      <td>Please do not add nonsense to Wikipedia. Such edits are considered vandalism and quickly undone. If you would like to experiment, please use the sandbox instead. Thank you.   -</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000247e83dcc1211</td>\n",
       "      <td>:Dear god this site is horrible.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00025358d4737918</td>\n",
       "      <td>\" \\n Only a fool can believe in such numbers. \\n The correct number lies between 10 000 to 15 000. \\n Ponder the numbers carefully.  \\n\\n This error will persist for a long time as it continues to reproduce... The latest reproduction I know is from ENCYCLOPÆDIA BRITANNICA ALMANAC 2008 wich states \\n Magnittude: 8.7 (fair enough) \\n victims: 70 000 (today 10 000 to 15 000 is not \"\"a lot\"\" so I guess people just come out with a number that impresses enough, I don't know. But I know this: it's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00026d1092fe71cc</td>\n",
       "      <td>== Double Redirects == \\n\\n When fixing double redirects, don't just blank the outer one, you need edit it to point it to the final target, unless you think it's inappropriate, in which case, it needs to be nominated at WP:RfD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  \\\n",
       "0  00001cee341fdb12   \n",
       "1  0000247867823ef7   \n",
       "2  00013b17ad220c46   \n",
       "3  00017563c3f7919a   \n",
       "4  00017695ad8997eb   \n",
       "5  0001ea8717f6de06   \n",
       "6  00024115d4cbde0f   \n",
       "7  000247e83dcc1211   \n",
       "8  00025358d4737918   \n",
       "9  00026d1092fe71cc   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          comment_text  \n",
       "0                                                                                                                                      Yo bitch Ja Rule is more succesful then you'll ever be whats up with you and hating you sad mofuckas...i should bitch slap ur pethedic white faces and get you to kiss my ass you guys sicken me. Ja rule is about pride in da music man. dont diss that shit on him. and nothin is wrong bein like tupac he was a brother too...fuckin white boys get things right next time.,  \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                 == From RfC == \\n\\n The title is fine as it is, IMO.  \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                           \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lapland —  /  \"  \n",
       "3                                                                                                                                                                                                                                                                                                        :If you have a look back at the source, the information I updated was the correct form. I can only guess the source hadn't updated. I shall update the information once again but thank you for your message.  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                            I don't anonymously edit articles at all.  \n",
       "5                                                                                                                                                                                                                                                                                                                                                                                                                     Thank you for understanding. I think very highly of you and would not revert without discussion.  \n",
       "6                                                                                                                                                                                                                                                                                                                                     Please do not add nonsense to Wikipedia. Such edits are considered vandalism and quickly undone. If you would like to experiment, please use the sandbox instead. Thank you.   -  \n",
       "7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     :Dear god this site is horrible.  \n",
       "8  \" \\n Only a fool can believe in such numbers. \\n The correct number lies between 10 000 to 15 000. \\n Ponder the numbers carefully.  \\n\\n This error will persist for a long time as it continues to reproduce... The latest reproduction I know is from ENCYCLOPÆDIA BRITANNICA ALMANAC 2008 wich states \\n Magnittude: 8.7 (fair enough) \\n victims: 70 000 (today 10 000 to 15 000 is not \"\"a lot\"\" so I guess people just come out with a number that impresses enough, I don't know. But I know this: it's ...  \n",
       "9                                                                                                                                                                                                                                                                                   == Double Redirects == \\n\\n When fixing double redirects, don't just blank the outer one, you need edit it to point it to the final target, unless you think it's inappropriate, in which case, it needs to be nominated at WP:RfD  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2281c42f358>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lenofcomment=train.comment_text.str.len()\n",
    "sns.set()\n",
    "sns.distplot(lenofcomment,bins=20,kde=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the comments are short with only a few longer than 1000 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'comment_text', 'malignant', 'highly_malignant', 'rude', 'threat',\n",
       "       'abuse', 'loathe'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "malignant           15294\n",
       "highly_malignant     1595\n",
       "rude                 8449\n",
       "threat                478\n",
       "abuse                7877\n",
       "loathe               1405\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[['malignant', 'highly_malignant', 'rude', 'threat','abuse', 'loathe']].sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that there is much imbalance in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemma= WordNetLemmatizer()\n",
    "import string\n",
    "def cleaning(text):\n",
    "    text=text.lower()\n",
    "    tokens=word_tokenize(text)\n",
    "    no_punctext=[w for w in tokens if w not in string.punctuation]\n",
    "    words=[w for w in no_punctext if w.isalpha()]\n",
    "    words=[w for w in words if w not in stopwords.words('english')]\n",
    "    cleanwords=[lemma.lemmatize(w) for w in words]\n",
    "    cleantext=' '.join(cleanwords)\n",
    "    return cleantext\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train['comment_text'])):\n",
    "    train['comment_text'][i]=cleaning(train['comment_text'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test['comment_text'])):\n",
    "    test['comment_text'][i]=cleaning(test['comment_text'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect=TfidfVectorizer()\n",
    "x=vect.fit_transform(train['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect=TfidfVectorizer()\n",
    "test=vect.fit_transform(test['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "sparse.save_npz(\"x.npz\", x)\n",
    "sparse.save_npz(\"x_test.npz\", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "x=sparse.load_npz(\"x.npz\")\n",
    "test=sparse.load_npz(\"x_test.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=train.iloc[:,2:-1].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.898660\n",
       "1    0.040565\n",
       "3    0.029122\n",
       "2    0.021996\n",
       "4    0.009062\n",
       "5    0.000595\n",
       "dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report,roc_curve,roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=0,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.9005681818181818\n",
      "[[43014     7     0     0     0     0]\n",
      " [ 1940     0     0     2     0     0]\n",
      " [ 1046     0     0     7     0     0]\n",
      " [ 1296     0     0    98     0     0]\n",
      " [  315     2     0   117     0     0]\n",
      " [   23     0     0     5     0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95     43021\n",
      "           1       0.00      0.00      0.00      1942\n",
      "           2       0.00      0.00      0.00      1053\n",
      "           3       0.43      0.07      0.12      1394\n",
      "           4       0.00      0.00      0.00       434\n",
      "           5       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           0.90     47872\n",
      "   macro avg       0.22      0.18      0.18     47872\n",
      "weighted avg       0.82      0.90      0.86     47872\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnb=MultinomialNB()\n",
    "mnb.fit(x_train,y_train)\n",
    "pred=mnb.predict(x_test)\n",
    "print('accuracy score:',accuracy_score(y_test,pred))\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.9034717580213903\n",
      "confusion matrix \n",
      " [[42980    27     7     6     0     1]\n",
      " [ 1857    39    24    21     1     0]\n",
      " [  924    32    48    34    12     3]\n",
      " [ 1135    22    61   138    38     0]\n",
      " [  299     3    19    67    44     2]\n",
      " [   18     0     1     3     4     2]]\n",
      "\n",
      " classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     43021\n",
      "           1       0.32      0.02      0.04      1942\n",
      "           2       0.30      0.05      0.08      1053\n",
      "           3       0.51      0.10      0.17      1394\n",
      "           4       0.44      0.10      0.17       434\n",
      "           5       0.25      0.07      0.11        28\n",
      "\n",
      "    accuracy                           0.90     47872\n",
      "   macro avg       0.46      0.22      0.25     47872\n",
      "weighted avg       0.86      0.90      0.87     47872\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(x_train,y_train)\n",
    "knn.score(x_train,y_train)\n",
    "pred=knn.predict(x_test)\n",
    "print('accuracy score',accuracy_score(y_test,pred))\n",
    "print('confusion matrix \\n',confusion_matrix(y_test,pred))\n",
    "print('\\n classification report \\n',classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset is severely imbalanced and Accuracy would not be the appropriate metric to choose the best model. ROC_AUC Curve would be a better metric\n",
    "to compare the performance of the models. ROC_AUC Curve is a straight forward process for binary label, but in this case the label is\n",
    "a multi class. I have to explore further the methods of constructing ROC curves for multi class classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of converting the multi label to a single columnn by adding the multi label columns, I tried multilearn Scikit and LabelPowerset\n",
    "keeping the multilabel columns  as it is i.e y is of multiple columns. Memory error occured due to huge data sets.Given below is the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from skmultilearn.model_selection import iterative_train_test_split\n",
    "#x_train,x_test,y_train,y_test=iterative_train_test_split(x,y.values,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.linear_model import LogisticRegression\n",
    "#from skmultilearn.problem_transform import LabelPowerset\n",
    "#from sklearn.metrics import accuracy_score,confusion_matrix,classification_report,roc_curve,roc_auc_score\n",
    "#model=LabelPowerset(LogisticRegression())\n",
    "#model.fit(x_train,y_train)\n",
    "#pred=model.predict(x_test)\n",
    "#print('accuracy score:',accuracy_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
